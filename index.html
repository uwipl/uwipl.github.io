<!DOCTYPE html>
<!-- Template by Quackit.com -->
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="">
    <meta name="author" content="">
    <link rel="icon" href="favicon.ico">


    <title>Information Processing Lab</title>

    <!-- Latest compiled and minified CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.3/css/bootstrap.min.css" integrity="sha384-MIwDKRSSImVFAZCVLtU0LMDdON6KVCrZHyVQQj6e8wIEJkW4tvwqXrbMIya1vriY" crossorigin="anonymous">

    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uHw+nqUivzIebhndOJK28anvf" crossorigin="anonymous">

    <link rel="stylesheet" href="assets/css/main.css"/>

  </head>

  <body data-spy="scroll" data-target="#topNav">

    <nav id="topNav" class="navbar navbar-full navbar-fixed-top navbar-dark" style="background-color: #4b2e83;">
        <div class="container">
            <button class="navbar-toggler hidden-md-up pull-right" type="button" data-toggle="collapse" data-target="#collapsingNavbar">
                &#9776;
            </button>
            <a class="navbar-brand" href="index.html">
                <img src="images/logo/ipl-logo-white-50x30.png">
            </a>
            <div class="collapse navbar-toggleable-sm" id="collapsingNavbar">
                <ul class="nav navbar-nav">
                    <li class="nav-item">
                        <a class="nav-link" href="people.html">People</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="projects.html">Projects</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="publication.html">Publication</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="https://github.com/ipl-uw" target="_blank">Software</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="life.html">Life</a>
                    </li>
                </ul>
            </div>
        </div>
    </nav>

    <div class="jumbotron jumbotron-billboard">
        <div class="img"></div>
        <div class="container jumbotron-title">
            <div class="row">
                <div class="col-lg-12">
                    <h1 class="display-4"><strong>Information Processing Lab</strong></h1>
                    <br>
                    <h4>
                        <i class="fas fa-university"></i> University of Washington 
                        &nbsp;&nbsp;
                        <i class="fas fa-map-marker-alt"></i> Seattle, WA
                    </h4>
                    <br>
                    <p class="lead">
                        Main research thrust of our current work is in the multimedia signal processing,
                        multimedia networking and machine learning areas. A specific focus is on the large scale smart
                        camera networks analytics and networking. The research group works under the guidance of
                        <a href="https://people.ece.uw.edu/hwang/" target="_blank">Prof. Jenq-Neng Hwang</a>.
                    </p>
                    <!-- <br><a href="#" class="btn btn-success btn-lg">Sign Up</a> -->
                </div>
            </div>
        </div>
    </div>

    <div class="container">
        <section id="news">
            <h2 class="display-4">News</h2><br>
            <ul class="news-bullet">
              <li>
                    <span class="tag tag-pill tag-success">2022/09/14</span>
                    <i>GLIPv2: Unifying Localization and Vision-Language Understanding</i> was accepted by the NeurIPS 2022 (25.6% acceptance rate)! Congratulation to Haotian!!!
                </li>
              <li>
                    <span class="tag tag-pill tag-success">2022/08/31</span>
                    Our team won the 3rd place of the SportsMOT Track of DeeperAction Challenge at ECCV 2022! Congraulations to Hsiang-Wei, Chris and Dr.Kim!
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2022/06/21</span>
                    <i>Grounded Language-Image Pre-training</i> was selected as the one of the 33 finalists for the Best Paper Award at CVPR 2022! 
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2022/06/20</span>
                    <i>GaitTAKE: Gait Recognition by Temporal Attention and Keypoint-guided Embedding</i> was accepted by the IEEE International Conference on Image Processing! Congratulation to Dr.Hsu, Yizhou and Chris!
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2022/06/20</span>
                    <i>HCIL: Hierarchical Class Incremental Learning for Longline Fishing Visual Monitoring</i> was accepted by the IEEE International Conference on Image Processing! Congratulation to Jay!
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2022/06/03</span>
                    Jiarui successfully defended her Ph.D. thesis: "Towards visual recognition in the wild." today! Congratulations to
                    Dr.Cai üë©üèª‚Äçüéì! üéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâüéâ
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2022/05/23</span>
                    We'll like share the news that <a href="https://attend.ieee.org/mmsp-2022/call-for-papers/">IEEE MMSP 2022</a>, which will be held on September 26‚Äì28, 2022 in Shanghai, China is now calling for paper!
                        <p align="center"><img src="images/news/MMSP2022-CFP.png" alt="" style="width:500px;border:1px solid;height:600px;"></p>
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2022/05/16</span>
                        We are pleased to share the news the the Data Scientist/AI/ML position (The <a href="https://www.usajobs.gov/job/654683600/print">DE</a> and <a href="https://www.usajobs.gov/job/654681800/print">MAP</a> announcements for the  Interdisciplinary Computer Scientist/Physical Scientist/Fish Biologist, ZP-1550/1301/0482-3/4) in the FATES Advanced Tech Branch has been posted.
                        The announcements will be open for 14- days, from 05/17/22 to 05/30/22, please refer to the links for additional info!
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2022/04/25</span>
                        <i>Unsupervised Severely Deformed Mesh Reconstruction (DMR) from a Single-View Image for Longline Fishing</i> was accepted by the IEEE ICME 2022 Workshop on 3D Multimedia Analytics, Search and Generation (3DMM)! Congratulation to Jay!
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2022/04/25</span>
                        <i>GolfPose: Golf Swing Analyses with A Monocular Camera based Human Pose Estimation</i> was accepted by the IEEE ICME 2022: The 3rd Artificial Intelligence in Sports (AI-Sports) Workshop! Congratulation to Zhongyu and Haorui!
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2022/03/06</span>
                    <i>Unsupervised Domain Adaptation Learning for Infant Pose Recognition with Synthetic Data</i> was accepted by the IEEE ICME 2022 (29% acceptance rate)! Congratulation to Chris and Zhongyu!
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2022/03/02</span>
                    <i>Grounded Language-Image Pre-training</i> was accepted by the CVPR 2022 (25.33% acceptance rate)! Congratulation to Haotian!
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2021/12/01</span>
                    <i>LUNA: Localizing Unfamiliarity Near Acquaintance for Open-set Long-Tailed Recognition</i> was accepted by the AAAI 2022 (15% acceptance rate)! Congratulation to Jiarui, Yizhou and Hung-Min!
                </li>
                <li>
                <li>
                    <span class="tag tag-pill tag-success">2021/10/17</span>
                    Our team is the üèÜwinner of Video Track (in both MOTChallenge-STEP and KITTI-STEP dataset) in the
                    <a href="https://motchallenge.net/workshops/bmtt2021/">6th BMTT Challenge</a> (in conjunction with ICCV 2021)!
                    <div class="row">
                        <div class="imgContainer">
                            <p align="center"><img src="images/news/bmtt2021_mots.png" alt="" style="height:200px;border: 1px solid"></p>
                        </div>
                        <div class="imgContainer">
                            <p align="center"><img src="images/news/bmtt2021_kitti.png" alt="" style="height:200px;border: 1px solid"></p>
                        </div>                    
                    </div>
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2021/10/16</span>
                    Our team won the ü•â3rd place of Camera-View Track in the
                    <a href="https://iccv2021-mmp.github.io/">ICCV 2021 Multi-camera Multiple People Tracking Workshop </a>!
                    <p align="center"><img src="images/news/mmp2021_certificate.png" alt="" style="width:350px;border:1px solid"></p>
                    <p align="center"><img src="images/news/mmp2021.gif" alt="" style="width:500px;height:;"></p>
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2021/09/09</span> Professor Hwang will be the guest editor for a special issue: <a href="https://www.mdpi.com/journal/applsci/special_issues/DL_Multi_Data">"Deep Learning from Multi-Sourced Data" for Applied Sciences</a>. Welcome to submitted original research, applications, and review articles in all areas related to learning from multi-souced data!
                    <p align="center"><img src="images/news/cfp_AS_SI.JPG" alt="" style="width:500px;border:1px solid;height:600px;"></p>

                </li>
                <li>
                    <span class="tag tag-pill tag-success">2021/08/09</span>
                    Li Chen successfully defended his Ph.D. thesis today. Congratulations to
                    Dr. Chen! üéâüéâüéâ
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2021/07/22</span>
                    Two papers from IPL:
                    <i>ACE: Ally Complementary Experts for Solving Long-Tailed Recognition in One-Shot (Oral)</i>
                    and
                    <i>Track without Appearance: Learn Box and Tracklet Embedding with Local and Global Motion Patterns for Vehicle Tracking</i>
                    were accepted and select as oral by the ICCV 2021! Congratuations Jiarui and Gaoang!
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2021/03/22</span>
                    We won the Honorable Mention Award in NTIRE 2021 Challenge on Multi-modal Aerial View Object Classification (in conjunction with CVPR 2021)!
                    <p align="center"><img src="images/news/ntire2021_certificate.png" alt="" style="width:350px;border:1px solid"></p>
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2021/01/01</span>
                    We are organizing the Radar Object Detection Challenge (ROD2021) at <a href="http://icmr2021.org/challenges.html">ACM ICMR 2021</a>. Welcome your participation! <a href="https://www.cruwdataset.org/rod2021">[Challenge Website]</a> <a href="https://competitions.codalab.org/competitions/28019">[Registration & Leaderboard]</a>
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2020/06/11</span>
                    Our team is the winner of track 3 (multi-object tracking and segmentation in KITTI-MOTS and MOTS20 dataset with public detection)
                    and the runner-up of track 2 (multi-object detection, tracking and segmentation in KITTI-MOTS dataset) in the
                    5th BMTT Challenge</a> in CVPR 2020 workshop. <a href="news/2020-06-11-cvpr20-bmtt.html">[Details...]</a>
                    <p align="center"><img src="images/news/bmtt2020.png" alt="" style="width:300px;border:1px solid"></p>
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2020/06/05</span>
                    Renshu Gu successfully defended her Ph.D. thesis today. Congratulations to Dr. Gu! üéâüéâüéâ
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2020/05/04</span>
                    Li Chen and his colleagues in <a href="https://rad.washington.edu/research/groups/vascular-imaging-laboratory/">Vascular Imaging Laboratory</a> won the <a href="https://newsroom.heart.org/news/seattle-scientist-wins-competition-for-artificial-intelligence-research">competition</a> for artificial intelligence research by American Heart Association and Amazon Web Services through a collaborative data grant initiative (Automated Vessel Wall Screening to Predict Cardiovascular Risk) funded by AHA. Congatulations, Li!
                    <br>
                    <a href="https://newsroom.uw.edu/postscript/knee-mris-can-depict-cardiovascular-risk-ai-affirms-it" target="_blank"><span class="tag tag-pill tag-default"><i class="far fa-file-alt"></i> UW Daily News</span></a>
                    <a href="https://www.radiologybusiness.com/topics/artificial-intelligence/radiology-amazon-american-heart-association-mri" target="_blank"><span class="tag tag-pill tag-default"><i class="far fa-file-alt"></i> Media Cover</span></a>

                </li>

                <li>
                    <span class="tag tag-pill tag-success">2019/10/25</span>
                    Three papers from IPL:
                    <i>Eye in the Sky: Drone-Based Object Tracking and 3D Localization</i>,
                    <i>Monocular Visual Object 3D Localization in Road Scenes</i>
                    <a href="http://yizhouwang.net/blog/2019/07/15/object-3d-localization/" target="_blank"><i class="fas fa-link"></i></a>,
                    <i>Exploit the connectivity: Multi-object tracking with trackletnet</i> are accepted as orals in
                    <a href="https://acmmm.org/">ACM MultiMedia 2019</a>.
                    Congratuations Haotian, Yizhou and Gaoang! üëç
                    <br>
                    <a href="https://dl.acm.org/citation.cfm?doid=3343031.3350924" target="_blank"><span class="tag tag-pill tag-default"><i class="far fa-file-alt"></i> Eye in the Sky </span></a>
                    <a href="https://arxiv.org/pdf/1910.08259.pdf" target="_blank"><span class="tag tag-pill tag-default"><i class="far fa-file-alt"></i> Object 3D Localization </span></a>
                    <a href="https://arxiv.org/abs/1811.07258" target="_blank"><span class="tag tag-pill tag-default"><i class="far fa-file-alt"></i> TrackletNet</span></a>
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2019/06/16</span>
                    Our team representing the University of Washington is the Winner of Track 1 (City-Scale Multi-Camera Vehicle Tracking) and the Runner-up of Track 2 (City-Scale Multi-Camera Vehicle Re-Identification) and Track 3 (Traffic Anomaly Detection) at the <a href="https://www.aicitychallenge.org/">AI City Challenge</a> in <a href="http://cvpr2019.thecvf.com/">CVPR 2019</a>. 
                    <a href="news/2019-06-16-cvpr19-aicity.html">[Details...]</a>
                    <br>
                    <a href="https://www.ece.uw.edu/spotlight/ece-team-wins-competition-in-ai-challenges/"><span class="tag tag-pill tag-default"><i class="far fa-newspaper"></i> UWECE News</span></a>
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2019/06/15</span>
                    Three Ph.D. graduate from our lab this year. Congratulations to Dr. Tang, Dr. Wang, and Dr. Huang! üéâüéâüéâ 
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2019/04/01</span>
                    Professor Hwang is interviewed by The Wall Street Journal. 
                    <a href="news/2019-04-01-hwang-wsj-full-text.html">[Full Text]</a>
                    <br>
                    <a href="https://www.wsj.com/articles/how-many-fish-are-there-in-the-sea-ai-can-find-the-answer-11554155162"><span class="tag tag-pill tag-default"><i class="fas fa-link"></i> WSJ Article</span></a>
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2018/06/18</span>
                    Our team representing the University of Washington is the Winner of Track 1 (Traffic Flow Analysis) and the Winner of Track 3 (Multi-camera Vehicle Detection and Reidentification) at the <a href="https://www.aicitychallenge.org/">AI City Challenge Workshop</a> at <a href="http://cvpr2018.thecvf.com/">CVPR 2018</a>. 
                    <a href="news/2018-06-18-aic-cvpr-2018.html">[Details...]</a>
                    <br>
                    <a href="http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w3/Tang_Single-Camera_and_Inter-Camera_CVPR_2018_paper.pdf"><span class="tag tag-pill tag-default"><i class="far fa-file-alt"></i> Paper</span></a>
                    <a href="https://github.com/zhengthomastang/2018AICity_TeamUW"><span class="tag tag-pill tag-default"><i class="fas fa-code"></i> Code</span></a>
                    <a href="https://youtu.be/_i4numqiv7Y"><span class="tag tag-pill tag-default"><i class="fas fa-video"></i> Track1 Demo</span></a>
                    <a href="https://youtu.be/Jlvh_KxHl40"><span class="tag tag-pill tag-default"><i class="fas fa-video"></i> Track3 Demo</span></a>
                    <a href="http://www.ee.washington.edu/spotlight/hwangs-team-beats-out-the-competition-in-ai-challenges/"><span class="tag tag-pill tag-default"><i class="far fa-newspaper"></i> UWEE News</span></a>
                </li>
                <li>
                    <span class="tag tag-pill tag-success">2017/08/05</span>
                    Our group is the Winner of Track 2 (AI City Applications Track) at the <a href="http://smart-city-conference.com/AICityChallenge/">2017 IEEE Smart World NVIDIA AI City Challenge</a>. 
                    <a href="news/2017-08-05-aic-2017.html">[Details...]</a>
                    <br>
                    <a href="https://blogs.nvidia.com/blog/2017/08/09/ai-city-challenge/"><span class="tag tag-pill tag-default"><i class="far fa-newspaper"></i> Nvidia Blog</span></a>
                </li>
            </ul>
            <br><br>
        </section>
    </div>

    <div class="container">
        <div class="footer">
            <br>
            <p>&copy; 2021 IPL@UW</p>
            <br>
        </div>
    </div> <!-- /container -->


    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->

    <!-- jQuery library -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.0.0/jquery.min.js" integrity="sha384-THPy051/pYDQGanwU6poAc/hOdQxjnOEXzbT+OuUAFqNqFjL+4IGLBgCJC3ZOShY" crossorigin="anonymous"></script>

    <!-- Tether -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/tether/1.2.0/js/tether.min.js" integrity="sha384-Plbmg8JY28KFelvJVai01l8WyZzrYWG825m+cZ0eDDS1f7d/js6ikvy1+X+guPIB" crossorigin="anonymous"></script>

    <!-- Latest compiled JavaScript -->
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.3/js/bootstrap.min.js" integrity="sha384-ux8v3A6CPtOTqOzMKiuo3d/DomGaaClxFYdCu2HPMBEkf6x2xiDyJ7gkXU0MWwaD" crossorigin="anonymous"></script>

    <!-- Initialize Bootstrap functionality -->
    <script>
    // Initialize tooltip component
    $(function () {
      $('[data-toggle="tooltip"]').tooltip()
    })

    // Initialize popover component
    $(function () {
      $('[data-toggle="popover"]').popover()
    })
    </script>    

  </body>
</html>
